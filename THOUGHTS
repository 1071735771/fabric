## Thoughts about config (mostly-answered)

* Re: below, right now invoke.Config auto-loads on __init__, and thus so do
  Connection() objects, as they have a default Config() instance if none is
  given.
    * So unless we change this, we (re)load conf files into a new
      Config on every host in the lib use case, and probably only once in the
      CLI use case (since we'd do what Invoke does and create a single Config
      at the start, handing copies of it into each task invoke).
    * Still seems like this is "correct" anyways, the users being surprised by
      having to manually load (or those who know about it and are just
      inconvenienced by having to do it all the damn time, and then being
      confused when they forget) will have bad feels, and if advanced users
      complain, we can add an opt-out somehow (such as a Connection subclass
      which creates that default Config with a 'load=False' flag set or w/e)
* do we load (ssh, other) config files in the lib case by default, or no?
    * Cleaner to let the user control when/how this occurs; arguably we can't
      even do it by "default" in lib situation because we dunno what they're
      doing, unless we do it in eg Context/Connection.___init__
    * But if we do it by default in CLI use case, now CLI and lib differ in a
      possibly surprising way.
    * And if we don't do it by default anywhere, that is itself surprising as
      it is to users of Fab 1 who expect at least SSH config to be loaded.
* Think of a few use cases re: the ssh_config, inv/fab configs, host-specific
  configs, loading, and how they would work / merge / where they would live:
    * Lib base case of "literally just Connection(foo).run(bar)": probably n/a?
        * To get conf file loads, Connection(foo,
          context=Context(load=True)).run(bar) or whatever? Implies we want
          Context or similar able to generate Connection objects so we can do
          Context().get_connection(foo).run(bar)?
        * Or, as above, does Connection(foo) implicitly load ssh_config et al?
        Such that Connection(my_foo_alias) connects to foo?
    * CLI base case of "fab -H foo -- bar" - same as above? or, as per Q, does
      it implicitly load after all?
    * CLI semi-base case of having single task def + "fab -H foo mytask" -
      ditto
    * CLI slightly less base case of referencing a role or other pool within
      task?
    * Lib case of same - do we do eg Pool(name) to load some pool config?
        * Should Pool be the same as eg clusto pool or Fab 1 role?
        * Our tutorial implies it's a manual hostname list but that's probably
          silly / not common. Almost all the time you'd want to reference your
          own array/list, or some data structure resulting in same.
        * Do we have some structure above Pool which yields Pools? Context
          again? Something mapping to a truth db? What does it look like in the
          semi base "I just have a fabfile and an ssh_config" case?
    * Clusto-driven use case specifically: what would I love to replace servo's
      innards with, which pulls from Clusto mostly, but honors CLI overrides
      and some smaller local in-code overrides (which we don't actually do
      anymore but used to, eg host exclude list)


## Newer specific questions to answer

* Is Pool worth having in the tutorial (or at all)?
* What sort of construct do we want - if any - for the equivalent of 'roles'?
  Anything in this space is going to ape, and almost definitely fall short of,
  APIs like those found in clusto or CM systems.
    * If we were to just say "do whatever" - people will still invent their own
    similar but distinct way of organizing things, and/or are likely to ask "how
    should I?"


## Non-specific recent thoughts

Deal with discrepancy between full control by default (zero extra printing /
just hook up the streams, i.e. what Local does), partial printing (print
stdout/err, with host prefixes) and full fab 1 style (print what you're doing,
stdout/stderr w/ prefixes, and when you're done - tho maybe never print when
done because that's kinda silly?)

----

* how does parallel work by default? clearly the superuser answer is "do it
  yourself using Connection objects" but what about the average user? is it a
  kwarg to e.g. Pool.execute()? separate method(s)? function taking a pool arg?
* the 'two types of serial' should probs be handled with: if you want one
  command on all hosts, then another  command on all hosts, just use subsequent
  calls to Pool.run(); if you want a set of commands on one host, then on
  another host, use Pool.execute()?
* how to handle the possibility of 'inner' execute's should that be a thing?
  e.g. someone defines a task, it gets explicitly or implicitly execute()'d
  against a pool, but inside it, it calls execute() on another pool? Tho this
  is a problem we face now too and it'd be more explicit in a pool-method
  scenario than it is in fab 1.x, at least.


## Older but probably still valid thoughts

* The expected host/host-collection-oriented API can probably be effected via
  invoke.Context subclasses - since that's exactly what they are (contexts for
  execution) and Context would provide an existing API for the same shit (like
  .run; settings/configuration crap; etc).
* sudo() and local() should probably be implemented as a 'via' kwarg on
  ctx.run?
    * How to handle the 'run locally or remotely, intelligently' feature
      request? I think just by having the class itself be smart about it? I.e.
      if you're "running on localhost" that implies the Context would be the
      Invoke default, or some other obviously-not-ssh-related class
      implementing a local runner.
        * I guess ambiguity would still exist if you're not using the
          context-based API - but that should probably not be allowed in Fab
          itself because it just doesn't fly. You'd be explicitly using
          invoke.run there? There would be no 'from fabric import run'.
    * Does not solve the situation where one's 'host' is literally 'localhost'
      (versus being unspecified/blank as in Fab 1 ) but I don't think that was
      the common case - the common case was running a task function with no
      host list.


## Context managers

NEWER THOUGHT: don't have them? We have literal contexts now, so we can do eg:

    ctx.cd('foo')
    ctx.run('ls') # is implicitly run('cd foo && ls')
    ctx.cd('bar')
    ctx.run('ls') # cd foo/bar && ls

OTOH it might be nice to still have context managers for the "auto close"
behavior, since in the above, getting back to "normal" requires e.g.
`ctx.run('cd ../..')`. OTOOH, shell scripting does this too.

Implementation-wise we could probably just have the context itself mutate
instead of spawning a new object as I was discussing below earlier, i.e. `with
ctx.cd():` instead of `with ctx.cd() as sub_ctx`.

Maybe we implement a jump queue sort of thing? Is this even worth this much
thought?

---

General implementation: these methods on Context (or Connection, etc) spawn a
new object which is basically a callback of sorts - it's given a link to the
context, the argument(s) given to the method (e.g. the path to cd to; the
settings to change; etc) and some way of altering that context on both
__enter__ and __exit__.

The "obvious" way of doing the latter is:

* pass an attribute name + a mutator function to this new object
* it then backs up, to itself, the current value at time of __enter__,
  replacing it with the mutated value
* in __exit__ it updates the parent with the older, preserved attribute value.

Could alter this slightly by having the mutator functions (lamdas) implemented
as other methods on Context and pass their name to the sub-object. However, the
sub-object would still need the attribute info so it could perform backup; and
restoration would then require setters which just feels silly.

### cd, lcd

As now, implemented with a list of paths that gets join'd on use.

May want to rename cd() to rcd() - people continue to be confused by cd() and
assume it applies locally.

lcd() should be something implemented in Invoke (and stands to reason cd()
would also - just w/ different target setting names so they remain distinct.)

### hide, show

Assuming hiding/showing is implemented similar to fab 1 (BIG assumption) - same
as cd, just tickles context state.

Should really be handled by Invoke, eh? And ideally log-based in some fashion.

May want to split things up:

* stdout/err, due to being stream based, are simply local defaults for run()'s
  kwargs. So these might just become regular settings and not deserving of
  their own contextmanager methods?
* Everything else are local line-based output levels and would thus just fit
  well into a real logging framework. So would need to implement that in a way
  that fits w/ the logging setup. So that might also be slightly different and
  live under a single, non-hide/show set of methods (tho possibly still context
  manager?)

tl;dr do we even want contextmanagers for this? They started out as the ONLY
way to hide things, but now that the API can do it per-run(), it may not make a
ton of sense.

### path, prefix

These should also be more generic and Invoke-ish since they can apply to
command running in general. But probably remain lists under the hood.

### remote_tunnel

Spawns new channels & sockets to handle the port forwards, tracks those in apparently-global state within fabric.contextmanagers (i.e. just inside the function itself? not sure why that works, the body should rerun every time the context manager is used) and hands a ThreadHandler to Paramiko which actually spins it up to forward ports.

So, probably needs a decently sized rewrite to be clean n such; only real Fab stuff it uses is the connection dict / env.host_string.

### settings

Likely replaced by whatever settings API is exposed in Context. Maybe try to get a sense of what settings folks frequently use it for now, besides nesting hide/show + warn_only + host_string. Suspect that would be bulk of it?

Then again the ability to run with temporarily different context for arbitrary stuff is handy. Meh.

### shell_env

Tracks a dict in Context, same as lcd/cd would with their lists? Once again, can probably roll into regular settings-y things.

### warn_only

Same as hide/show re: stdout/err - might not _need_ to be contextmanager anymore, just given as per-run() kwarg or tickled in Context settings junk.


## Decorators

### hosts, roles

Currently, tells execute() what the default host list should be if nothing is
given. Almost entirely oriented around the CLI use case. Does it make any sense
in the library case?

Thought experiment: if we went the "Fab just a lib, use it with invoke"
route...how would @hosts/@roles work? I think they'd just be hints to Invoke's
Executor saying "please vectorize over this value when you call this task",
right? (Would need to really be saying "vectorize over this value, turn it into
Connection/Batch, then stuff in as first argument".)

That puts them on the same footing as any other vectorization. Meaning - they
can go away in favor of whatever easy-vectorization option is added to Invoke.
How would THAT look?

* yet moar args to @task?
* a second decorator used in tandem with @task?
* a function or class used to create another "task" that is a combo of a
  regular task + the vectorization? (That's really not THAT different from a
  new decorator, other than it not replacing the original task.)

### runs_once, parallel, serial

Should not be necessary? Guess it ties into "global host list" - if a given
session can be given a default host list for vectorizing tasks, then we do need
a way to indicate whether a task should be exempt from that. E.g. if we still
allow this:

    $ fab -H a,b,c runonce hostcrap morehostcrap

then `runonce` does need a way to tell the CLI junk that it should not be run
once each for the host list.

If we assume all Fabric tasks are contextualized, "local" or "runs once" tasks
still look no different from "normal" ones. So it's the execution mechanism
that has to differentiate between "I run this N times for this vector of
Connections" versus "I run this once with a single non-connection-oriented
Context".

Feels like cleanest solution is to do away with "global" host lists entirely
and force ALL such invocations to be what in Fab 1 are "meta" tasks. I.e. if
you had tasks 'foo' and 'bar' and wanted them to both run on the same host
list, and task 'biz' that should run only once, you would need to write task
'go' like so:

    @task
    def go(ctx, hosts):
        b = Batch(ctx, hosts)
        b.execute(foo)
        b.execute(bar)
        ctx.execute(biz)

and invoke:

    $ fab go --hosts a,b,c

This removes the ability to arbitrarily change up which tasks you run on which
hosts, all at the CLI level, so not 100% sure.

Main problem with @runs_once (and the other decorators) is they make it hard to
tell who should override who - normally CLI rules all, and @runs_once in Fab 1
is one of the unusual things that inverts control. It's impossible to run a
@runs_once task more than one time from the CLI.

Perhaps we have Fabric contexts splice in common per-task options
automatically, so you could do e.g.::

    $ fab -H a,b,c foo bar biz --once

Here, the Executor would automatically vectorize tasks over the core host list,
but if it saw 'once=True', it would not do so. Or alternately, the part of
Invoke that sets up the Executor would just select the default instead of the
Fabric host-running one? That also works well for choosing serial, parallel etc
on a per-task basis.

So e.g.:

    fab -H a,b,c --parallel foo bar biz --once

or

    fab -H a,b,c --parallel foo bar biz --serial baz --once

Where the core options set the default executor and per-task flags override. 

(--parallel etc would be sugar for --executor=parallel or maybe
--strategy=parallel.)

ANYWAY - so with the above strategy, this gives us complete CLI control over invocation, and we can have a per-task (kwarg-level probably) way of setting the default that task "wants" to be run as. So we'd still have @runs_once, but it's normalized now and on the same footing as parallel/serial.

#### More thoughts on executing

In Invoke, Executor currently is responsible for:

* taking collection + context
* looking up a task name in a collection
* calling it with CLI flag-args and the context
* calling its pre- and post- tasks before and/or after

and it is created once and then used throughout the 'session' (i.e. each task/context becomes my_executor.execute(task, ...)).

Idea was to subclass it to add more things like how to deal with pre/post, how to run in serial/parallel, etc.

However this doesn't fly with switching up executor/strategy per-task, as above. Would want to instantiate the executor once per parser context, at least niavely. However we then lose ability to track how many times a given task has been called 'globally' which is almost definitely required for nontrivial pre/post/dependency shit.

So perhaps we split things up a bit, with collection management (including call tracking) in one object, and actual invocation/execution in another. Main problem is this requires communication, so we need a way for the latter to inform the former that it just ran tasks foo, bar, biz and baz N times.



### task

Simply a subclass or wrapper for Invoke's. Would have contextualized=True always (perhaps not even letting you set it to False - a "Fabric" task is meaningless without its host context).

May end up just being a straight reimport of Invoke's, if all functionality can be pushed therein (like strategy selection).

### with_settings

TK

Rest also TK


## Connection junk

Thinking of Connection (primary user facing class with run(), put() etc) but also Host (name, aliases, possibly also IP address and such) (and therefore also HostCollection?), User (name, but could expose remote user stuff such as group/uid/gid/etc) and maybe Port (number, not sure what else honestly.)

Problem with Host and User in this context is that having them be independent objects - at least in the sense I was considering (pass them into Connection(), use string arg values as shorthands for convenience) - doesn't fly because if they were kept around independent of a given Connection, none of the Connection specific attributes/methods (eg User('jforcier') - there's no context implied there, it might have a different uid/gid depending on connection.)

May just mean that the initial "take a rich object, allow string args" idea is dumb and it should just be "give me string args, I will figure out how to populate myself with specific-to-me instances of these useful objects", wherein instances of Host and User are explicitly tied to their Connection.

Host is a snag here because one reason to make it objectlike is to have N names, aka aliases, so that we understand Connection('web1') should result in the same core host object as Connection('my-default-webhost') should the user configure things that way / have an SSH config implying such.

Really means the model needs to be many-to-one, a given Host or User could be associated with N Connections. They differ though, Hosts can be singletons of sorts (besides the alias implication which is easily solved via a map in Context) but Users need to be namespaced by Host.

So perhaps it should really be that a Connection references a Host (unless it stores only the string and we use an eg Lexicon mapping to handle aliasing, as we do in Invoke) and...also the string identifying the User, which is then delegated to Host to look up (so we get that host's instance of that user)?

<!-- vim: set ft=markdown : -->
