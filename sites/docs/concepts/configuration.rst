=============
Configuration
=============

The heart of Fabric's configuration system (as with much of the rest of Fabric)
relies on an Invoke component, namely `invoke.config.Config`. In core Invoke,
`~invoke.config.Config` objects are generated by developers themselves or by
the CLI module, and given to `~invoke.context.Context` objects, which
host the primary API.

Fabric's use is similar: it starts both the library and CLI use cases with
default settings such as port number and username. This is merged with data
loaded from similar file locations as in Invoke (e.g. ``/etc/fabric.yml``,
``~/.fabric.yml``), and SSH config files (e.g. ``~/.ssh/config``).

This merged `~.invoke.config.Config` is then given to Fabric's `.Connection`
objects, making it available to internal connection machinery and user-facing
code.

TODO: QUESTIONS

* do we load (ssh, other) config files in the lib case by default, or no?
    * Cleaner to let the user control when/how this occurs; arguably we can't
      even do it by "default" in lib situation because we dunno what they're
      doing, unless we do it in eg Context/Connection.___init__
    * But if we do it by default in CLI use case, now CLI and lib differ in a
      possibly surprising way.
    * And if we don't do it by default anywhere, that is itself surprising as
      it is to users of Fab 1 who expect at least SSH config to be loaded.
* Think of a few use cases re: the ssh_config, inv/fab configs, host-specific
  configs, loading, and how they would work / merge / where they would live:
    * Lib base case of "literally just Host(foo).run(bar)": probably n/a?
        * To get conf file loads, Host(foo,
          context=Context(load=True)).run(bar) or whatever? Implies we want
          Context or similar able to generate Host objects so we can do
          Context().get_host(foo).run(bar)?
        * Or, as above, does Host(foo) implicitly load ssh_config et al? Such
          that Host(my_foo_alias) connects to foo?
    * CLI base case of "fab -H foo -- bar" - same as above? or, as per Q, does
      it implicitly load after all?
    * CLI semi-base case of having single task def + "fab -H foo mytask" -
      ditto
    * CLI slightly less base case of referencing a role or other pool within
      task?
    * Lib case of same - do we do eg Pool(name) to load some pool config?
        * Should Pool be the same as eg clusto pool or Fab 1 role?
        * Our tutorial implies it's a manual hostname list but that's probably
          silly / not common. Almost all the time you'd want to reference your
          own array/list, or some data structure resulting in same.
        * Do we have some structure above Pool which yields Pools? Context
          again? Something mapping to a truth db? What does it look like in the
          semi base "I just have a fabfile and an ssh_config" case?
    * Clusto-driven use case specifically: what would I love to replace servo's
      innards with, which pulls from Clusto mostly, but honors CLI overrides
      and some smaller local in-code overrides (which we don't actually do
      anymore but used to, eg host exclude list)


----

TODO: EXPANDME

* Fabric simply seeks for specific configuration settings in an Invoke config
  object, either one handed explicitly into its own API objects like Connection
  or Pool, or a default one; describe its defaults as we do for Invoke (user,
  port etc).
* Fabric's CLI driver generates Connections and Pools for you and hands in that
  default config (initializing it with CLI options and so forth, just like
  Invoke does)

    * TODO: actually, this means that Invoke's CLI/Executor stuff needs
      further override capability which Fabric's CLI module uses? to wit:

        * additional (or different?) CLI flags like port, user, connection
          related opts
        * different file prefixes, e.g. ~/.fabric.yaml and /etc/fabric.yaml

            * should it ALSO honor invoke files? i.e. find both? What would
              users leveraging both tools expect?

        * intersect of those two, like -f finding a fabfile instead of an
          invoke task file?

* Users who have a nontrivial, non-CLI-based setup (eg celery workers or some
  such) should manage their own 'base' Config file as well as their own
  Connection/Pool generation?

    * What would this look like? If I have, say, a 5 module codebase not using
      CLI tasks, where would I store my in-code config settings (or my
      initialization of a Config object which loads conf files - i.e. replacing
      what the CLI module does), and how would I be setting up explicit
      Connections and Pools?

        * E.g. write some sample Jenkins/Celery esque background worker code -
          how does this work, how does it feel?

    * Feels strongly tied to #186 - regardless of whether one has real CLI
      tasks where shared state is in a Context, or if it's non-CLI oriented and
      shared state is "only" in the Config, it is the same problem:

        * What's your code/session entry point?
        * How do you share state throughout a session?

* How should ssh_config (from paramiko) figure into this?

    * Best is probably to just bridge it with our own stuff instead of slapping
      the entire thing in some subset of our config?

        * E.g. top level `Port` and `User` override our values
        * Host configs should generate new semi-implicit host configs in the
          Fabric level (however we do that...?) when none exist elsewhere in
          the places we source from; and merge otherwise.

            * Which brings us to how we DO load hosts from config files exactly
              presumably as part of the same general config loading setup, with
              option for loading 1+ on top of the "core" one?
            * How to hook into config management DBs like Clusto, Chef Server?
            * How to handle people who want their own Ansible-like setup of a
              bunch of host, collection of host, or role config files to all
              load in? Don't necessarily expect their setup, but make it easy
              for them to use our API to load one...

        * So say a user has some random arse yaml files they load configs from;
          and they also have ~/.ssh/config; how do we merge these, which one
          wins?

            * Actual merging should almost definitely still use regular Config
              merge stuff - allow arbitrary levels to be defined in between the
              regular ones and use the same merging behavior?
            * Then all we need to do is figure out which source comes
              above/below which other sources. Probably ~/.ssh/config
              below/overridden by anything more explicitly loaded?
