=========================================
Frequently Asked/Answered Questions (FAQ)
=========================================

These are some of the most commonly encountered problems or frequently asked
questions which we receive from users. They aren't intended as a substitute for
reading the rest of the documentation, especially the :doc:`conceptual docs
<concepts>`, so please make sure you check those out if your question is not
answered here.


.. _one-shell-per-command:

My (``cd``/``workon``/``export``/etc) calls don't seem to work!
===============================================================

While Fabric can be used for many shell-script-like tasks, there's a slightly
unintuitive catch: each `~fabric.connection.Connection.run` or
`~fabric.connection.Connection.sudo` call has its own distinct shell session.
This is required in order for Fabric to reliably figure out, after your command
has run, what its standard out/error and return codes were.

Unfortunately, it means that code like the following doesn't behave as you
might assume::

    @task
    def deploy(c):
        c.run("cd /path/to/application")
        c.run("./update.sh")

If that were a shell script, the second `~fabric.connection.Connection.run`
call would have executed with a current working directory of
``/path/to/application/`` -- but because both commands are run in their own
distinct session over SSH, it actually tries to execute ``$HOME/update.sh``
instead (since your remote home directory is the default working directory).

A simple workaround is to make use of shell logic operations such as ``&&``,
which link multiple expressions together (provided the left hand side executed
without error) like so::

    def deploy(c):
        c.run("cd /path/to/application && ./update.sh")

.. TODO: reinsert mention of 'with cd():' if that is reimplemented

.. note::
    You might also get away with an absolute path and skip directory changing
    altogether::

        def deploy(c):
            c.run("/path/to/application/update.sh")

    However, this requires that the command in question makes no assumptions
    about your current working directory!


.. TODO:
    reinstate FAQ about 'su' / running as another user, when sudo grows that
    back

.. TODO: move the below to Invoke, it is not SSH specific!

Why do I sometimes see ``err: stdin: is not a tty``?
====================================================

This message is typically generated by programs such as ``biff`` or ``mesg``
lurking within your remote user's ``.profile`` or ``.bashrc`` files (or any
other such files, including system-wide ones.) Fabric's default mode of
operation involves executing a shell in "login mode", which causes these files
to be executed.

Because Fabric also doesn't bother asking the remote end for a tty by default
(as it's not usually necessary) programs fired within your startup files, which
expect a tty to be present, will complain -- and thus, stderr output about
"stdin is not a tty" or similar.

There are multiple ways to deal with this problem:

.. TODO: change references to `env`/etc

* Find and remove or comment out the offending program call. If the program was
  not added by you on purpose and is simply a legacy of the operating system,
  this may be safe to do, and is the simplest approach.
* Override ``env.shell`` to remove the ``-l`` flag. This should tell Bash not
  to load your startup files. If you don't depend on the contents of your
  startup files (such as aliases or whatnot) this may be a good solution.
* Pass ``pty=True`` to `run` or `sudo`, which will force allocation of a
  pseudo-tty on the remote end, and hopefully cause the offending program to be
  less cranky.


.. _faq-daemonize:

Why can't I run programs in the background with ``&``? It makes Fabric hang.
============================================================================

Because SSH executes a new shell session on the remote end for each invocation
of ``run`` or ``sudo`` (:ref:`see also <one-shell-per-command>`), backgrounded
processes may prevent the calling shell from exiting until the processes stop
running, which in turn prevents Fabric from continuing on with its own
execution.

The key to fixing this is to ensure that your process' standard pipes are all
disassociated from the calling shell, which may be done in a number of ways
(listed in order of robustness):

* Use a pre-existing daemonization technique if one exists for the program at
  hand -- for example, calling an init script instead of directly invoking a
  server binary.

    * Or leverage a process manager such as ``supervisord``, ``upstart`` or
      ``systemd`` - such tools let you define what it means to "run" one of
      your background processes, then issue init-script-like
      start/stop/restart/status commands. They offer many advantages over
      classic init scripts as well.

* Use ``tmux``, ``screen`` or ``dtach`` to fully detach the process from the
  running shell; these tools have the benefit of allowing you to reattach to
  the process later on if needed (though they are more ad-hoc than
  ``supervisord``-like tools).
* Run the program under ``nohup`` or similar "in-shell" tools - note that this
  approach has seen limited success for most users.
